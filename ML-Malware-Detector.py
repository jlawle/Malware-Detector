import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
from PIL import Image
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D, Rescaling
import numpy as np
import pathlib
import tensorflow as tf
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt

# Loop through dataset directory of files to run model against
curr_path = os.path.dirname(os.path.realpath(__file__))
train_path = curr_path + r"\dataset\train" + "\\"

cat_names = os.listdir(train_path)
# print(cat_names)

# link: https://www.tensorflow.org/tutorials/images/classification
train_dir = pathlib.Path(train_path)
image_count = len(list(train_dir.glob('*/*.png')))

batch_size = 32
img_height = 256
img_width = 256

modelname = '5Epoch_256x256_malware_model.h5'

answer = input("Re-run model compilation? (Y/N)")
# answer = "n"

train_ds = tf.keras.utils.image_dataset_from_directory(
  train_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  train_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = train_ds.class_names
# print(class_names)

if answer == 'Y' or answer == 'y':
  AUTOTUNE = tf.data.AUTOTUNE

  train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
  val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

  normalization_layer = Rescaling(1./255)

  normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
  image_batch, labels_batch = next(iter(normalized_ds))
  first_image = image_batch[0]
  # Notice the pixel values are now in `[0,1]`.
  # print(np.min(first_image), np.max(first_image))

  num_classes = len(os.listdir(train_path))

  model = Sequential([
    Rescaling(1./255, input_shape=(img_height, img_width, 3)),
    Conv2D(16, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Conv2D(32, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Conv2D(64, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(num_classes)
  ])

  model.compile(optimizer='adam',
                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                metrics=['accuracy'])

  model.summary()

  epochs=10
  history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs
  )

  model.save(modelname)

  acc = history.history['accuracy']
  val_acc = history.history['val_accuracy']

  loss = history.history['loss']
  val_loss = history.history['val_loss']

  epochs_range = range(epochs)

  plt.figure(figsize=(8, 8))
  plt.subplot(1, 2, 1)
  plt.plot(epochs_range, acc, label='Training Accuracy')
  plt.plot(epochs_range, val_acc, label='Validation Accuracy')
  plt.legend(loc='lower right')
  plt.title('Training and Validation Accuracy')
  plt.savefig("acc.png")

  plt.figure(figsize=(8,8))
  plt.subplot(1, 2, 2)
  plt.plot(epochs_range, loss, label='Training Loss')
  plt.plot(epochs_range, val_loss, label='Validation Loss')
  plt.legend(loc='upper right')
  plt.title('Training and Validation Loss')
  plt.savefig("loss.png")

if answer != 'Y' or answer != 'y':
  model = load_model(modelname)
test_path = curr_path + r"\dataset\validation" + "\\"

test_dir = pathlib.Path(test_path)

# test_data = tf.keras.utils.image_dataset_from_directory(
#   test_path,
#   validation_split=None,
#   subset=None,
#   seed=123,
#   image_size=(img_height, img_width),
#   batch_size=batch_size
# )
data_dict = {}
missed_val = {}
directory = test_path
for subdir in os.listdir(directory):

  # print(subdir + ":")
  correct = 0
  incorrect  = 0
  FN=0
  FP=0
  missed_val[subdir] = []
  for file in os.listdir(test_path + subdir):
    # print(test_path + subdir + "\\" + file)
    im_path = test_path + subdir + "\\" + file
    img = tf.keras.utils.load_img(
      im_path,
      target_size=(img_height, img_width)
    )
    img_array = tf.keras.utils.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)  # Create a batch

    predictions = model.predict(img_array)
    score = tf.nn.softmax(predictions[0])

    if class_names[np.argmax(score)] == subdir:
      correct += 1
    else:
      incorrect += 1
      missed_val[subdir].append(class_names[np.argmax(score)])
    if subdir == "Benign" and class_names[np.argmax(score)] != subdir:
      FP += 1
    elif subdir != "Benign" and class_names[np.argmax(score)] == "Benign":
      FN += 1
      # print(class_names[np.argmax(score)] + " " + str(100 * np.max(score)))
  data_dict[subdir] = {}
  data_dict[subdir]['Correct'] = correct
  data_dict[subdir]['Incorrect'] = incorrect
  data_dict[subdir]['FN'] = FN
  data_dict[subdir]['FP'] = FP
  # print("False Positive: {}\nFalse Negative: {}".format(FP, FN))
  # print("Correct: {} Incorrect: {}".format(correct, incorrect))
  # print()

print(data_dict)
print(missed_val)


X_axis = np.arange(len(cat_names))

for val in X_axis:
  plt.bar(val - 0.2, data_dict[cat_names[val]]["Correct"], 0.4, label='Correct' if val == 0 else "", color='black')
  plt.bar(val + 0.2, data_dict[cat_names[val]]["Incorrect"], 0.4, label='Incorrect' if val == 0 else "", color='red')

plt.figure(figsize=(10, 6))
plt.xticks(X_axis, cat_names, rotation=45)
plt.xlabel("Test Groups")
plt.ylabel("Number of Correct/Incorrect")
plt.title("Correct vs. Incorrect Identifications")
plt.legend()
plt.savefig("bars.png")

# Perform data post-processing (combine similar virus types)